#!/usr/bin/env python

# stdlib imports
import argparse
import os.path
import sys
import locale
import warnings

warnings.simplefilter("ignore")

# third party imports
import pandas as pd
import numpy as np
from mapio.shake import getHeaderData

# local imports
from losspager.models.exposure import Exposure
from losspager.models.econexposure import EconExposure
from losspager.models.emploss import EmpiricalLoss
from losspager.models.semimodel import SemiEmpiricalFatality
from losspager.utils.country import Country
from losspager.utils.config import read_config


COUNTRY = Country()
TIMEFMT = "%Y-%m-%d %H:%M:%S"


def pandify_semi(fatbystruct):
    """Turn the fatalities by structure into DataFrame suitable for printing.

    :param fatbystruct:
      Dictionary of country code, fatality dictionary:
        - (key,value) of (building type,number of fatalities)
    :returns:
      pandas DataFrame with columns (Country Code,Building Type 1,
             Building Type 2, ...) and index of country codes.
    """
    # figure out what all of the unique building types are...
    utypes = []
    for ccode, fatstruct in fatbystruct.items():
        for key in fatstruct.keys():
            if key not in utypes:
                utypes.append(key)

    newfatbystruct = {}
    for utype in utypes:
        newfatbystruct[utype] = []
    ccodes = []
    for ccode, fatstruct in fatbystruct.items():
        ccodes.append(ccode)
        # ccodes are the rows in our new dictionary
        for utype in utypes:
            if utype not in fatstruct:
                newfatbystruct[utype].append(np.nan)
            else:
                newfatbystruct[utype].append((fatstruct[utype]))

    d1 = pd.DataFrame(newfatbystruct, index=ccodes)
    return d1


def pandify_exposure(exposure, human_readable=False):
    """Turn the exposure dictionary into a DataFrame suitable for printing.

    :param exposure:
      exposure dictionary as returned by Exposure.calcExposure().
    :param human_readable:
      Boolean indicating whether exposure values should be printed as human
      readable (i.e, "1,234" not "1234").
    :returns:
      Pandas DataFrame containing the rows of exposure to shaking.
    """
    columns = ["Country Code"]
    mmi = ["MMI%i" % i for i in range(1, 11)]
    columns = columns + mmi
    rows = {}
    for col in columns:
        rows[col] = []
    for ccode, array in exposure.items():
        if ccode == "maximum_border_mmi":
            continue
        if human_readable and ccode.find("Total") < 0:
            cname = COUNTRY.getCountry(ccode)["Name"]
            rows["Country Code"].append(cname)
        else:
            rows["Country Code"].append(ccode)
        for arrvalue, mmicol in zip(array, mmi):
            rows[mmicol].append(int(arrvalue))
    df = pd.DataFrame(rows, columns=columns, dtype=np.int64)
    df = df.set_index("Country Code")

    # shuffle the rows so that they are sorted by country codes,
    # then total at the end
    ccols = df.index.tolist()
    is_economic = False
    if ccols.count("TotalExposure"):
        ccols.remove("TotalExposure")
    if ccols.count("TotalEconomicExposure"):
        is_economic = True
        ccols.remove("TotalEconomicExposure")
    ccols.sort()
    if is_economic:
        ccols += ["TotalEconomicExposure"]
    else:
        ccols += ["TotalExposure"]
    df = df.reindex(ccols)

    if human_readable:
        # set the locale to that specified by the system
        locale.setlocale(locale.LC_ALL, "")
        sep = locale.localeconv()["thousands_sep"]
        fmt = "{:%sd}" % sep
        for mmicol in mmi:
            df[mmicol] = df[mmicol].map(fmt.format)
    return df


def pandify_losses(lossdict, losstype="fatality", human_readable=False):
    """Turn the loss dictionaries into DataFrames suitable for printing.

    :param lossdict:
      loss dictionary as returned by EmpiricalLoss.getLosses().
    :param losstype:
      One of 'fatality','economic'.
    :param human_readable:
      Boolean indicating whether exposure values should be printed as human
      readable (i.e, "1,234" not "1234").
    :returns:
      Pandas DataFrame containing the rows of losses due to shaking.
    """
    if losstype == "fatality":
        losscol = "Fatalities"
        totalrow = "TotalFatalities"
    else:
        losscol = "Dollars Lost"
        totalrow = "TotalDollars"

    columns = ["Country Code", losscol]
    rows = {"Country Code": []}
    rows[losscol] = []
    for ccode, lossvalue in lossdict.items():
        if human_readable and ccode.find("Total") < 0:
            cname = COUNTRY.getCountry(ccode)["Name"]
            rows["Country Code"].append(cname)
        else:
            rows["Country Code"].append(ccode)
        rows[losscol].append(lossvalue)
    df = pd.DataFrame(rows, columns=columns, dtype=np.uint64)
    df = df.set_index("Country Code")
    # shuffle the rows so that they are sorted by country codes,
    # then total at the end
    ccols = df.index.tolist()
    ccols.remove(totalrow)
    ccols.sort()
    ccols += [totalrow]
    df = df.reindex(ccols)
    if human_readable:
        # set the locale to that specified by the system
        locale.setlocale(locale.LC_ALL, "")
        sep = locale.localeconv()["thousands_sep"]
        fmt = "{:%sd}" % sep
        df[losscol] = df[losscol].map(fmt.format)

    return df


def main(pargs, config):
    # Make sure grid.xml file exists
    if not os.path.isfile(pargs.gridfile):
        print(f"ShakeMap Grid file {pargs.gridfile} does not exist.")
        sys.exit(1)

    # get all the basic event information and print it, if requested
    shake_tuple = getHeaderData(pargs.gridfile)
    etime = shake_tuple[1]["event_timestamp"]
    elat = shake_tuple[1]["lat"]
    elon = shake_tuple[1]["lon"]
    edepth = shake_tuple[1]["depth"]
    emag = shake_tuple[1]["magnitude"]
    eid = shake_tuple[1]["event_id"]
    location = shake_tuple[1]["event_description"]
    if args.eventinfo:
        print("Event Information:")
        print(f"Location : {location}")
        print(f"Time : {etime.strftime(TIMEFMT)}")
        print(f"Latitude : {elat:.4f}")
        print(f"Longitude : {elon:.4f}")
        print(f"Depth : {edepth:.1f}")
        print(f"Magnitude : {emag:.1f}")
        print(f"Event ID : {eid}")

    # get the year of the event
    event_year = shake_tuple[1]["event_timestamp"].year

    # find the population data collected most closely to the event_year
    pop_year = None
    tmin = 10000000
    popfile = None
    for popdict in config["model_data"]["population_data"]:
        popyear = popdict["population_year"]
        popgrid = popdict["population_grid"]
        if not os.path.isfile(popgrid):
            print(f"Population grid file {popgrid} does not exist.")
            sys.exit(1)
        if abs(popyear - event_year) < tmin:
            tmin = abs(popyear - event_year)
            pop_year = popyear
            popfile = popgrid

    if pargs.debug:
        sys.stderr.write(
            "Population year: %i Population file: %s\n" % (pop_year, popfile)
        )

    # Get exposure results
    isofile = config["model_data"]["country_grid"]
    expomodel = Exposure(popfile, pop_year, isofile)
    try:
        exposure = expomodel.calcExposure(pargs.gridfile)
    except Exception as e:
        sys.stderr.write(
            f'Failed to calculate exposure using {pargs.gridfile} as input:  "{e}\"\n'
        )
        sys.exit(0)
    expdf = pandify_exposure(exposure, human_readable=pargs.readable)
    if not args.total_exposure:
        print("Population Exposure to Shaking:\n")
        print(expdf)
        print()
    else:
        exposures = [str(col) for col in expdf.iloc[-1].tolist()]
        row = ",".join([eid] + exposures)
        print(row)

    # get fatality results, if requested
    if pargs.fatalities:
        fatmodel = EmpiricalLoss.fromDefaultFatality()
        fatdict = fatmodel.getLosses(exposure)
        fatdf = pandify_losses(
            fatdict, losstype="fatality", human_readable=pargs.readable
        )
        print("Fatalities Due to Shaking:\n")
        print(fatdf)
        print()

    # get economic results, if requested
    if pargs.econloss:
        econexpmodel = EconExposure(popfile, popyear, isofile)
        ecomodel = EmpiricalLoss.fromDefaultEconomic()
        econexposure = econexpmodel.calcExposure(pargs.gridfile)
        econexpdf = pandify_exposure(econexposure, human_readable=pargs.readable)
        print("Population Economic Exposure to Shaking:\n")
        print(econexpdf)
        ecodict = ecomodel.getLosses(econexposure)
        ecodf = pandify_losses(
            ecodict, losstype="economic", human_readable=pargs.readable
        )
        print("Dollar Losses Due to Shaking:\n")
        print(ecodf)

    # Get semi-empirical losses, if requested
    if pargs.semiloss:
        urbanfile = config["model_data"]["urban_rural_grid"]
        if not os.path.isfile(urbanfile):
            print(f"Urban-rural grid file {urbanfile} does not exist.")
            sys.exit(1)
        semi = SemiEmpiricalFatality.fromDefault()
        semi.setGlobalFiles(popfile, popyear, urbanfile, isofile)
        semiloss, resfat, nonresfat = semi.getLosses(pargs.gridfile)
        print("Fatalities according to Semi-Empirical model: %i\n" % semiloss)
        d1 = pandify_semi(resfat)
        print("Fatalities by residential building types:\n")
        print(d1)
        d2 = pandify_semi(nonresfat)
        print("\nFatalities by non-residential building types:\n")
        print(d2)


if __name__ == "__main__":
    desc = """Calculate PAGER exposures and losses (fatalities or economic).

    This program presumes that you have a configuration file in
    ~/.losspager/config.json, consisting of the following entries:

    {
      "model_data": {
        "population_data": [
          {
            "population_year": 2011,
            "population_grid": "/Users/user/pager/data/lspop2011.flt"
          },
          {
            "population_year": 2012,
            "population_grid": "/Users/user/pager/data/lspop2011.flt"
          }
        ],
        "country_grid": "/Users/user/pager/data/isogrid.bil",
        "urban_rural_grid": "/Users/user/pager/data/glurextents.bil"
    },
      "database": {
        "url": "sqlite:////Users/user/.losspager/losspager_schema.db"
      }
    }

    Example usage:
    %(prog)s grid.xml

    will print out exposures (per-country, and total)...
    Country MMI1 MMI2 MMI3 MMI4 MMI5  MMI6   MMI7    MMI8   MMI9 MMI10
    AF         0    0   10  100 1000 10000 100000 1000000 100000     0
    PK         0    0   10  100 1000 10000 100000 1000000 100000     0
    Total      0    0   20  200 2000 20000 200000 2000000 200000     0

    %(prog)s grid.xml -f
    will print out exposures and fatalities...
    Exposure:
    Country MMI1 MMI2 MMI3 MMI4 MMI5  MMI6   MMI7    MMI8   MMI9 MMI10
    AF         0    0   10  100 1000 10000 100000 1000000 100000     0
    PK         0    0   10  100 1000 10000 100000 1000000 100000     0
    Total      0    0   20  200 2000 20000 200000 2000000 200000     0

    Fatalities:
    Country         Losses
    AF              100000
    PK              100000
    TotalFatalities 200000

    %(prog)s grid.xml -f -e
    will print out exposures,fatalities, and economic losses...
    Exposure:
    Country MMI1 MMI2 MMI3 MMI4 MMI5  MMI6   MMI7    MMI8   MMI9 MMI10
    AF         0    0   10  100 1000 10000 100000 1000000 100000     0
    PK         0    0   10  100 1000 10000 100000 1000000 100000     0
    Total      0    0   20  200 2000 20000 200000 2000000 200000     0

    Fatalities:
    Country         Losses
    AF              100000
    PK              100000
    TotalFatalities 200000

    Economic Losses:
    Country  Dollars(USD)
    AF            1000000
    PK            1000000
    TotalDollars  2000000
    """
    formatter = argparse.RawDescriptionHelpFormatter
    parser = argparse.ArgumentParser(description=desc, formatter_class=formatter)
    parser.add_argument("gridfile", help="The path to a ShakeMap grid.xml file")
    parser.add_argument(
        "-f",
        "--fatalities",
        action="store_true",
        default=False,
        help="Calculate empirical fatalities",
    )
    parser.add_argument(
        "-e",
        "--econloss",
        action="store_true",
        default=False,
        help="Calculate empirical economic exposures and losses",
    )
    parser.add_argument(
        "-s",
        "--semiloss",
        action="store_true",
        default=False,
        help="Calculate semi-empirical fatalities",
    )
    parser.add_argument(
        "-r",
        "--readable",
        action="store_true",
        default=False,
        help="Print all numbers in human readable format",
    )
    parser.add_argument(
        "-d",
        "--debug",
        action="store_true",
        default=False,
        help="Print debug information (mostly useful to developers)",
    )
    parser.add_argument(
        "-i",
        "--eventinfo",
        action="store_false",
        default=True,
        help="Turn off printing of basic event information",
    )
    parser.add_argument(
        "-t",
        "--total-exposure",
        action="store_true",
        default=False,
        help="Print only exposure information, comma separated",
    )

    args = parser.parse_args()

    pd.set_option("display.width", 1000)
    pd.set_option("precision", 2)

    # read config file
    config = read_config()

    # Make sure model_data section exists
    try:
        config["model_data"]["population_data"][0]["population_year"]
        config["model_data"]["population_data"][0]["population_grid"]
        os.path.isfile(config["model_data"]["country_grid"])
        os.path.isfile(config["model_data"]["urban_rural_grid"])
    except:
        errmsg = "Config file %s is missing some or all of the required information.  See the help for the required format.\n"
        sys.stderr.write(errmsg)
        sys.exit(1)

    main(args, config)
