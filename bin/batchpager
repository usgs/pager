#!/usr/bin/env python

# stdlib imports
import os.path
import argparse
import shutil
import sys
import glob
from datetime import datetime

# third party imports
from impactutils.io.cmd import get_command_output
import numpy as np


PAGER_COMMAND = 'pagerlite'


class CustomFormatter(argparse.ArgumentDefaultsHelpFormatter,
                      argparse.RawDescriptionHelpFormatter):
    pass


def call_pagerlite(cmd, grids, logfile, outfile):
    """Loop over a list of event IDs, calling pagerlite on each one.

    Args:
        cmd (str): Path to pagerlite command.
        grids (list): List of paths to grid.xml files to process.
        logfile (file): Open file object where child process can write output.
    Returns:
        tuple:
            (Boolean indicating success/failure,
            stdout from pagerlite call,
            stderr from pagerlite call)
    """
    for grid in grids:
        cmdstr = '%s -it %s >> %s' % (cmd, grid, outfile)
        res, stdout, stderr = get_command_output(cmdstr)
        if not res:
            logfile.write('Failure for event %s: "%s" with command "%s"\n' %
                          (grid, stdout + stderr, cmd))
    return (res, stdout, stderr)


def main(args):
    # check for the existence of one of the pager programs
    pager_cmd = shutil.which(PAGER_COMMAND)
    if pager_cmd is None:
        print('Could not find "%s" on your path. Exiting.' % args.program)
        sys.exit(1)

    # now break up the input file into N chunks to process
    # read all the event ids
    events = open(args.file, 'rt').readlines()
    # remove trailing newline from each event
    events = [event.strip() for event in events]

    chunks = np.array_split(events, args.num_processes)
    homedir = os.path.expanduser('~')
    logbase = 'pager_batch_log_'
    outbase = 'pager_batch_stdout_'
    logfmt = logbase + '%i.txt'
    outfmt = outbase + '%i.txt'

    # now run each chunk in parallel.
    child_ids = []
    for i in range(0, len(chunks)):
        try:
            pid = os.fork()
        except OSError:
            sys.stderr.write("Could not create a child process\n")
            continue

        if pid == 0:
            chunk = chunks[i]
            childid = os.getpid()
            logfile = os.path.join(homedir, logfmt % childid)
            flog = open(logfile, 'wt')
            outfile = os.path.join(homedir, outfmt % childid)
            call_pagerlite(pager_cmd, chunk, flog, outfile)
            flog.close()
            os._exit(0)
        else:
            print("Parent: created child process %i." % pid)
            child_ids.append(pid)

    for i in range(0, len(chunks)):
        child_id, _ = os.waitpid(0, 0)
        print('Child process %i has finished.' % child_id)

    # read all the logfile content into a string, delete the logfiles...
    logfiles = glob.glob(os.path.join(homedir, logbase + '*'))
    errors = []
    for logfile in logfiles:
        content = open(logfile, 'rt').read()
        os.remove(logfile)
        if not len(content):
            continue
        errors.append(content)
    errorstring = '\n'.join(errors)
    if len(errorstring):
        print('Errors:\n')
        print(errorstring)

    # concatenate all of the output files into one file, ordered by the
    # child ids that we created.
    output = ''
    for childid in child_ids:
        idfile = os.path.join(homedir, outfmt % childid)
        data = open(idfile, 'rt').read()
        output += data
    todaystr = datetime.utcnow().strftime('%Y%m%d%H%M%S')
    outfile = os.path.join(homedir, 'pagerlite_%s.csv' % todaystr)
    print('Writing pagerlite results to %s' % outfile)
    with open(outfile, 'wt') as f:
        f.write(output)


if __name__ == '__main__':
    description = '''Population exposure in a batch process from a list of event IDs.

-n option should be chosen intelligently to be lower than the number of
cores present on the system.
    '''
    parser = argparse.ArgumentParser(description=description,
                                     formatter_class=CustomFormatter)
    parser.add_argument('file', help='Text file with one ID per line.')

    nphlp = ('Number of instances of pagerlite that should '
             'be run simultaneously. '
             'The value given to -n should generally be less than '
             'or equal to the number of cores on the machine.')
    parser.add_argument('-n', '--num-processes',
                        help=nphlp, default=4, type=int)

    pargs = parser.parse_args()
    main(pargs)
