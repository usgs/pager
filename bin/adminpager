#!/usr/bin/env python

# stdlib imports
import argparse
import sys
import os.path
import datetime
import collections
import zipfile
import shutil
import glob
from operator import attrgetter
from calendar import monthrange

# local imports
from losspager.utils.config import read_config, read_mail_config, get_mail_config_file
from losspager.io.pagerdata import PagerData
from losspager.utils.admin import (
    PagerAdmin,
    RemoteAdmin,
    transfer,
    unset_pending,
    get_id_and_source,
)
from losspager.utils.eventpath import get_event_folder
from losspager.utils.exception import PagerException


# third party imports
from impactutils.io.cmd import get_command_output
from impactutils.comcat.query import ComCatInfo
import pandas as pd

DATEFMT = "%Y-%m-%d"
DATETIMEFMT = "%Y-%m-%d %H:%M:%S"
NDAYS = 7
MAX_DAYS = 300 * 365  # maximum number of days to do queries for events
# this is a system call hack until I can refactor runpager to export a run function
PAGER_SCRIPT = "runpager.py"
TIMEFMT = "%Y-%m-%d %H:%M:%S"
HDRDICT = collections.OrderedDict(
    [
        ("ID", "%-10s"),
        ("Ver", "%-3s"),
        ("Time", "%-19s"),
        ("Mag", "%-4s"),
        ("Depth", "%-8s"),
        ("Level", "%-7s"),
        ("MMI", "%-3s"),
        ("Tsunami?", "%-8s"),
        ("Stopped?", "%-8s"),
        ("Location", "%-42s"),
    ]
)

LEVELS = {"green": 0, "yellow": 1, "orange": 2, "red": 3}


def run_pager(eventid):
    try:
        ccinfo = ComCatInfo(eventid)
        gridurl = ccinfo.getShakeGrid()
        cmd = f"pager {gridurl}"
        print(f'Running command "{cmd}"')
        res, stdout, stderr = get_command_output(cmd)
        return (res, stdout + stderr)
    except Exception:
        return (False, f"Could not open connection to ComCat for event {eventid}")


def order_event_data(event_data, sort_by=("time",)):
    if not isinstance(sort_by, tuple):
        raise PagerException("sort_by option must be a tuple of strings.")
    sort_options = ("time", "magnitude", "alert", "processing_time")
    for option in sort_by:
        if option not in sort_options:
            raise PagerException(f"Sort option {option} not allowed.")
    event_data = sorted(event_data, key=attrgetter(*sort_by))
    return event_data


def archive_event(event, archive_folder, output_folder):
    eventfolder = get_event_folder(event, output_folder)
    if eventfolder is None:
        return False
    zipname = os.path.join(archive_folder, event + ".zip")
    myzip = zipfile.ZipFile(zipname, mode="w", compression=zipfile.ZIP_DEFLATED)
    for root, dirs, files in os.walk(eventfolder):
        arcfolder = root[root.find(event) :]
        for fname in files:
            arcfile = os.path.join(arcfolder, fname)
            fullfile = os.path.join(root, fname)
            myzip.write(fullfile, arcfile)

    myzip.close()
    shutil.rmtree(eventfolder)
    return True


def is_date(datestr):
    try:
        datetime.datetime.strptime(datestr, DATETIMEFMT)
    except:
        try:
            datetime.datetime.strptime(datestr, DATEFMT)
        except:
            return False
    return True


def query_events_since(outfolder):
    pass


def get_all_events(outfolder):
    allevents = os.listdir(outfolder)
    events = []
    for event in allevents:
        if os.path.isdir(os.path.join(outfolder, event)):
            events.append(event)
    return events


def get_event_data(eventfolder):
    data_blobs = []
    for versionfolder in glob.glob(os.path.join(eventfolder, "version.*")):
        jsonfolder = os.path.join(versionfolder, "json")
        vdata = PagerData()
        vdata.loadFromJSON(jsonfolder)
        data_blobs.append(vdata)
    return data_blobs


def get_date(datestr):
    """datestr can be a datetime date or date/time string, OR 'all' or 'recent'.
    'recent' returns last two weeks of events, 'all' gets all events.
    """
    archdate = None
    if datestr == "all":
        archdate = datetime.datetime(1800, 1, 1)
    elif datestr == "recent":
        archdate = datetime.datetime.utcnow() - datetime.timedelta(days=14)
    else:
        try:
            archdate = datetime.datetime.strptime(datestr, DATETIMEFMT)
        except:
            try:
                archdate = datetime.datetime.strptime(datestr, DATEFMT)
            except:
                pass
    return archdate


def do_archive(archive_info, archive_threshold, admin):
    archive_date = get_date(archive_info[0])
    if archive_info[0] == "all":
        narchived, nerrors = admin.archive(all_events=True)
    elif archive_info[0] == "auto":
        tnow = datetime.datetime.utcnow()
        dt = datetime.timedelta(days=archive_threshold)
        archive_date = tnow - dt
        narchived, nerrors = admin.archive(events_before=archive_date)
    elif archive_date is not None:
        narchived, nerrors = admin.archive(events_before=archive_date)
    else:
        narchived, nerrors = admin.archive(events=archive_info)
    return (narchived, nerrors)


def do_release(eventid, admin, config):
    # find the most recent version of PAGER for this event
    event_folder = admin.getEventFolder(eventid)
    release_file = os.path.join(event_folder, "release")
    f = open(release_file, "wt")
    f.write("released\n")
    f.close()
    if event_folder is None:
        print(f"No event {eventid} found.  Exiting.")
        sys.exit(1)
    version_folder = admin.getLastVersion(event_folder)
    res = unset_pending(version_folder)
    if not res:
        return (res, "This event has already been released.")
    try:
        ccinfo = ComCatInfo(eventid)
        authid, allids = ccinfo.getAssociatedIds()
        authsource, allsources = ccinfo.getAssociatedSources()
    except:
        authid, authsource = get_id_and_source(version_folder)

    jsonfolder = os.path.join(version_folder, "json")
    pdata = PagerData()
    pdata.loadFromJSON(jsonfolder)
    try:
        msg = transfer(config, pdata, authid, authsource, version_folder, release=True)
    except Exception as e:
        msg = str(e)
    return (True, msg)


def do_force(eventid, admin, config, mailconfig):
    # find the most recent version of PAGER for this event
    event_folder = admin.getEventFolder(eventid)
    if event_folder is None:
        print(f"No event {eventid} found.  Exiting.")
        sys.exit(1)
    version_folder = admin.getLastVersion(event_folder)
    try:
        ccinfo = ComCatInfo(eventid)
        authid, allids = ccinfo.getAssociatedIds()
        authsource, allsources = ccinfo.getAssociatedSources()
    except:
        authid, authsource = get_id_and_source(version_folder)

    jsonfolder = os.path.join(version_folder, "json")
    pdata = PagerData()
    pdata.loadFromJSON(jsonfolder)
    event_time = pdata.time
    thresh = mailconfig["release_threshold"]
    email_threshold = event_time + datetime.timedelta(seconds=thresh * 3600)
    now_time = datetime.datetime.utcnow()
    user_msg = ""
    if now_time < email_threshold:
        user_msg += (
            "The current time is within the %i hour email limit - users may already have been notified.\n"
            % thresh
        )
    user_msg += "Are you sure you want to force sending of emails? Y/[N] "
    response = input(user_msg)
    if response != "Y":
        msg = "You chose not to force sending of emails. Exiting."
        return (False, msg)

    try:
        msg = transfer(
            config, pdata, authid, authsource, version_folder, force_email=True
        )
    except Exception as e:
        msg = str(e)
    return (True, msg)


def do_renotify(eventid, admin, config):
    # find the most recent version of PAGER for this event
    event_folder = admin.getEventFolder(eventid)
    if event_folder is None:
        print(f"No event {eventid} found.  Exiting.")
        sys.exit(1)
    version_folder = admin.getLastVersion(event_folder)
    try:
        ccinfo = ComCatInfo(eventid)
        authid, allids = ccinfo.getAssociatedIds()
        authsource, allsources = ccinfo.getAssociatedSources()
    except:
        authid, authsource = get_id_and_source(version_folder)

    jsonfolder = os.path.join(version_folder, "json")
    pdata = PagerData()
    pdata.loadFromJSON(jsonfolder)
    try:
        msg = transfer(config, pdata, authid, authsource, version_folder, renotify=True)
    except Exception as e:
        msg = str(e)
    return (True, msg)


def do_status(status, admin):
    # check the pager config first
    current_status = admin.getStatus()
    if status == "check":
        if current_status == "primary":
            msg = "PAGER PRIMARY: This system WILL transfer products."
        else:
            msg = "PAGER SECONDARY: This system WILL NOT transfer products."
    else:
        if status == current_status:
            msg = f"PAGER status is already {current_status}."
        else:
            new_status = admin.setStatus(status)
            if new_status == "primary":
                fmt = "PAGER status changed to %s - this system is now configured to transfer products."
            else:
                fmt = "PAGER status changed to %s - this system is now configured to NOT transfer products."
            msg = fmt % new_status

    # if the mail config file exists on this system, do the same actions on that file
    if get_mail_config_file() is not None:
        current_mail_status = admin.getMailStatus()
        if status == "check":
            if current_mail_status == "primary":
                msg2 = "\nMAIL PRIMARY: This system WILL send emails."
            else:
                msg2 = "\nMAIL SECONDARY: This system WILL NOT send emails."
        else:
            if status == current_mail_status:
                msg2 = f"\nMAIL status is already {current_mail_status}."
            else:
                new_status = admin.setMailStatus(status)
                if new_status == "primary":
                    fmt = "\nMAIL status changed to %s - this system is now configured to send email."
                else:
                    fmt = "\nMAIL status changed to %s - this system is now configured to NOT send email."
                msg2 = fmt % new_status

    msg += msg2
    return msg


def do_stats(stats, admin, config):
    if "stats_folder" not in config.keys():
        print("Configure the stats_folder variable first.")
        sys.exit(1)
    if not os.path.isdir(config["stats_folder"]):
        print(f"stats_folder {config['stats_folder']} does not exist.")
        sys.exit(1)
    tnow = datetime.datetime.utcnow()
    this_month = tnow.month
    if stats[0] == "month":
        # go get the last full month's worth of pager results.
        query_month = this_month - 1
        query_year = tnow.year
        if query_month == 0:
            query_month = 12
            query_year = tnow.year - 1
        ndays = monthrange(query_year, query_month)[1]
        start_date = datetime.datetime(query_year, query_month, 1)
        end_date = datetime.datetime(query_year, query_month, ndays, 23, 59, 59)
        fname = "monthly_%i_%i.xlsx" % (query_year, query_month)
    elif stats[0] == "quarter":
        this_quarter = (tnow.month - 1) // 3
        last_quarter = this_quarter - 1
        if last_quarter == -1:
            query_year = tnow.year - 1
            last_quarter = 3
        quarters = {0: (1, 3), 1: (4, 6), 2: (7, 9), 3: (10, 12)}

        end_month_days, tmp = monthrange(query_year, quarters[last_quarter][1])
        start_date = datetime.datetime(query_year, quarters[last_quarter][0], 1)
        end_date = datetime.datetime(
            query_year, quarters[last_quarter][1], end_month_days, 23, 59, 59
        )
        fname = "quarterly_%i_Q%i.xlsx" % (query_year, (last_quarter + 1))
    elif stats[0] == "year":
        query_year = tnow.year - 1
        start_date = datetime.datetime(query_year, 1, 1)
        end_date = datetime.datetime(query_year, 12, 31, 23, 59, 59)
        fname = "yearly_%i.xlsx" % (query_year)
    else:
        msg = f"Unsupported stats period {stats[0]}."
        res = False
    pdataframe, broken = admin.query(
        start_time=start_date,
        end_time=end_date,
        mag_threshold=0.0,
        alert_threshold="green",
        version="all",
    )
    pdataframe["tmp"] = pdataframe.index
    pdataframe = pdataframe.sort_values(["tmp", "Version"])
    pdataframe = pdataframe.drop("tmp", 1)
    statsfile = os.path.join(config["stats_folder"], fname)
    pdataframe.to_excel(statsfile)
    msg = f"All event statistics saved to {statsfile}."
    res = True
    return (res, msg)


def do_query(query, output, admin):
    msg = ""
    pd.set_option("display.width", 1000)
    pd.set_option("display.max_rows", 1000)
    start_date = get_date(query[0])
    # some scenarios are in the future.  Sigh.
    end_date = datetime.datetime(3000, 1, 1)
    mag_threshold = 0.0
    alert_threshold = "green"
    version = "last"
    qsyntax = "query syntax: [START/all [MAG [ALERT [END [VERSION]]]]]. "
    if start_date is None:
        msg = "Invalid start date %s. Returning."
        res = False
        return (res, msg)

    if len(query) >= 2:
        try:
            mag_threshold = float(query[1])
            assert mag_threshold >= 0 and mag_threshold <= 10.0
        except:
            msg = qsyntax + "Second argument must be a magnitude [0-10]."
            res = False
    if len(query) >= 3:
        alert_threshold = query[2]
        if alert_threshold not in ["green", "yellow", "orange", "red"]:
            msg = qsyntax + "Fourth argument must be one of (green,yellow,orange,red)."
            res = False
    if len(query) >= 4:
        end_date = get_date(query[3])
        if end_date is None:
            msg = qsyntax + "Third argument must be a date/time string."
            res = False
    if len(query) >= 5:
        version = query[4]
        if version not in ["first", "last", "eight", "all"]:
            msg = qsyntax + "Fifth argument must be one of (first,last,eight,all)."
            res = False

    pdataframe, broken_events = admin.query(
        start_time=start_date,
        end_time=end_date,
        mag_threshold=mag_threshold,
        alert_threshold=alert_threshold,
        version=version,
    )
    if output == "screen":
        if len(pdataframe):
            print(pdataframe)
            if len(broken_events):
                print("Events with no valid versions:")
                for broken in broken_events:
                    print(broken)
        else:
            print("No events on filesystem matching query criteria.")
        res = True
    else:
        fpath, fname = os.path.split(output)
        if not os.path.isdir(fpath):
            msg = f"Cannot create {fname} in {fpath} - directory does not exist."
            res = False
        pdataframe.to_excel(output)
        msg = "%i rows written to %s." % (len(pdataframe), output)
        res = True
    return (res, msg)


def main(args):
    # Get config file loaded
    config = read_config()

    # figure out where the output data goes
    pager_folder = config["output_folder"]

    # figure out where the archive folder is
    archive_folder = config["archive_folder"]

    # figure out auto archive threshold
    archive_threshold_days = config["archive_older_than"]
    archive_threshold = datetime.datetime.utcnow() - datetime.timedelta(
        days=archive_threshold_days
    )

    # if we're on a laptop, then status should not be set in the config at all
    if "status" not in config:
        if "pdl" in config:
            admin = RemoteAdmin(config["pdl"])
            action = ""
            eventid = ""
            if args.release:
                action = "release"
                eventid = args.release
            if args.status:
                action = "switch-status"
            if args.cancel:
                action = "cancel"
                eventid = args.cancel
            if args.renotify:
                action = "renotify"
                eventid = args.renotify
            if args.stop:
                action = "stop"
                eventid = args.stop
            if args.unstop:
                action = "unstop"
                eventid = args.unstop
            if action != "":
                print(
                    "You are not on a primary system, but have PDL configured.  Trying remote admin actions..."
                )
                res, stdout, stderr = admin.sendAction(action, eventid)
                if not res:
                    print(
                        f'Sending remote action {action} failed. "{stdout}", {stderr}".'
                    )
                    sys.exit(1)
                else:
                    print(
                        f'Successfully sent remote action {action}. "{stdout}".'
                    )
                    sys.exit(0)

    admin = PagerAdmin(pager_folder, archive_folder)

    if args.stop:
        result, eventfolder = admin.stop(args.stop)
        if result:
            print(f'A "stop" file was placed in {eventfolder}.')
        else:
            print(f'"stop" file already exists in {eventfolder}.')
        sys.exit(0)

    if args.run_event:
        eventid = args.run_event
        res, msg = run_pager(eventid)
        lines = msg.decode("utf-8").split("\n")
        for line in lines:
            print(line)
        if not res:
            sys.exit(1)
        else:
            sys.exit(0)

    if args.renotify:
        res, msg = do_renotify(args.renotify, admin, config)
        print(msg)
        if not res:
            sys.exit(1)
        else:
            sys.exit(0)

    if args.force_email:
        mail_config = read_mail_config()
        res, msg = do_force(args.force_email, admin, config, mail_config)
        print(msg)
        if not res:
            sys.exit(1)
        else:
            sys.exit(0)

    if args.unstop:
        result, eventfolder = admin.unstop(args.unstop)
        if result:
            print(f'A "stop" file was removed from {eventfolder}.')
        else:
            print(f'No "stop" file was found in {eventfolder}.')
        sys.exit(0)

    if args.archive:
        narchived, nerrors = do_archive(
            args.archive, config["archive_older_than"], admin
        )
        print(
            "%i events archived to %s, %i errors" % (narchived, archive_folder, nerrors)
        )
        sys.exit(0)

    if args.release:
        res, msg = do_release(args.release, admin, config)
        print(msg)
        if not res:
            sys.exit(1)
        else:
            sys.exit(0)

    if args.restore:
        if args.restore[0] == "all":
            nrestored = admin.restore(all_events=True)
        else:
            nrestored = admin.restore(events=args.restore)
        print("%i events restored to %s" % (nrestored, pager_folder))
        sys.exit(0)

    if args.status is not None:
        msg = do_status(args.status, admin)
        print(msg)
        sys.exit(0)

    if args.history:
        pd.set_option("display.width", 1000)
        pd.set_option("display.max_rows", 1000)
        pdataframe, broken_events = admin.query(eventid=args.history)
        pdataframe = pdataframe.sort_values("Version")
        if args.output == "screen":
            print(pdataframe)
            if len(broken_events):
                print("Events with no valid versions:")
                for broken in broken_events:
                    print(broken)
        else:
            pdataframe.to_excel(args.output)
            print("Saved %i versions to %s" % (len(pdataframe), args.output))
        sys.exit(0)

    if args.tsunami:
        if args.tsunami[1] not in ["on", "off"]:
            print("Tsunami syntax: adminpager --tsunami EVENT on/off")
            sys.exit(1)
        # toggling re-runs PAGER, including whatever transfer may happen
        result, stdout, stderr = admin.toggleTsunami(args.tsunami[0], args.tsunami[1])
        print(
            "Tsunami status has been set to %s for event %s"
            % (args.tsunami[1], args.tsunami[0])
        )
        if result:
            lines = stdout.decode("utf-8").split("\n")
            print("This event has been re-run successfully, with the output:")
            for line in lines:
                print(line)
        if not result:
            print(
                'This event has not been re-run successfully, with the output:"%s"'
                % (stderr)
            )
        sys.exit(0)

    if args.stats:
        res, msg = do_stats(args.stats, admin, config)
        print(msg)
        if not res:
            sys.exit(1)
        else:
            sys.exit(0)

    if args.query:
        res, msg = do_query(args.query, args.output, admin)
        print(msg)
        if res:
            sys.exit(0)
        else:
            sys.exit(1)


if __name__ == "__main__":
    desc = "Administer the PAGER system with a series of subcommands."
    usage = """
    System Status:
    To query the system status: "adminpager --status check"
    To switch the system from being primary to secondary: "adminpager --status secondary"
    To switch the system from being secondary to primary: "adminpager --status primary"

    Stopping/Unstopping PAGER updates:
    To prevent an event from being automatically updated: "adminpager --stop EVENTID"
    To re-allow an event to be automatically updated: "adminpager --unstop EVENTID"

    Archiving/Restoring events:
    To archive an event: "adminpager --archive EVENTID"
    To archive ALL events: "adminpager --archive all"
    To restore an event from the archives: "adminpager --restore EVENTID"

    Releasing/Renotifying events:
    To release an event: "adminpager --release EVENTID"
    To renotify for an event: "adminpager --renotify EVENTID"

    Setting tsunami flag for an event (will re-run PAGER):
    
    To toggle the tsunami flag ON for an event: "adminpager --tsunami EVENTID on"
    To toggle the tsunami flag OFF for an event: "adminpager --tsunami EVENTID off"
    To allow PAGER to use ComCat/magnitude to determine tsunami behavior: "adminpager --tsunami EVENTID auto"

    Querying existing events:
    To print a list of the events from the last 14 days: "adminpager --query recent"
    To see the version history of an event: "adminpager --history EVENTID"

    Full query Syntax:
    All events from December 15, 2015 to present: "adminpager --query 2015-12-15"
    M5.5+ events from December 15, 2016 to present: "adminpager --query 2015-12-15 5.5"
    All Yellow events > M5.5: "adminpager --query 1900-01-01 5.5 yellow"
    Yellow events > M5.5 until November 15, 2016: "adminpager --query 1900-01-01 5.5 yellow 2016-11-15"
    First version of yellow events > M5.5 until November 15, 2016: "adminpager --query 1900-01-01 5.5 yellow 2016-11-15 first"
    Last version of yellow events > M5.5 until November 15, 2016: adminpager --query 1900-01-01 5.5 yellow 2016-11-15 last"
    All versions of yellow events > M5.5 until November 15, 2016: adminpager --query 1900-01-01 5.5 yellow 2016-11-15 all
    First version of yellow events > M5.5 created 8+ hours after origin, until November 15, 2016: adminpager --query 1900-01-01 5.5 yellow 2016-11-15 eight

    Saving query results:
    Any query above can be saved to an Excel file by using the --output option: "adminpager --query recent --output ~/fortnight_results.xls"
    """
    argparser = argparse.ArgumentParser(
        description=desc,
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
        usage=usage,
    )
    archive_str = """Archive event(s) from file system. Passing "all" as an argument 
    will archive all events, passing "auto" will archive events based on pre-configured 
    number of days previous to current date, passing a date (YYYY-mm-dd) will archive
    all events prior to that date."""
    argparser.add_argument("--archive", nargs="*", help=archive_str, metavar="EVENT")
    argparser.add_argument(
        "--restore",
        nargs="*",
        help='Restore events from archive.  Passing "all" will restore all events from the archive.',
        metavar="EVENT",
    )

    argparser.add_argument(
        "--stop",
        help="Prevent event(s) from being re-run automatically.",
        metavar="EVENT",
    )
    argparser.add_argument(
        "--unstop",
        help="Allow stopped event(s) to be re-run automatically.",
        metavar="EVENT",
    )
    argparser.add_argument(
        "--status",
        choices=["check", "primary", "secondary"],
        help="Print or change PAGER (and also possibly PAGER MAIL) primary/secondary status.",
    )
    argparser.add_argument(
        "--tsunami",
        nargs=2,
        help="Toggle tsunami warning on PAGER alert",
        metavar=("EVENT", "on/off/auto"),
    )
    argparser.add_argument(
        "--query",
        nargs="*",
        metavar="PARAM",
        help="List events that match the query. Params are [START/all/recent [MAG [ALERT [END [VERSION]]]]].",
    )
    argparser.add_argument(
        "--history", help="Print history of input event.", metavar="EVENT"
    )
    argparser.add_argument(
        "--output",
        help="Select output format for queries ('screen' or excel filename.",
        default="screen",
        metavar="FORMAT",
    )
    argparser.add_argument(
        "--stats",
        nargs=1,
        help="Create dump of monthly, quarterly, or yearly PAGER results.",
        choices=("month", "quarter", "year"),
        metavar="PERIOD",
    )
    argparser.add_argument(
        "--release", help="Release orange/red alert level event.", metavar="EVENTCODE"
    )
    argparser.add_argument(
        "--force-email",
        help="Force sending of email to all appropriate users, ignoring email threshold (nominally 8 hours).",
        metavar="EVENTCODE",
    )
    argparser.add_argument(
        "--run-event",
        help="Run event based on event ID from ComCat.  Will fail if ShakeMap not found in ComCat.",
        metavar="EVENTCODE",
    )
    argparser.add_argument(
        "--renotify", metavar="EVENTCODE", help="Renotify users about an event."
    )
    argparser.add_argument("--cancel", nargs=1, help="Cancel event.", metavar="EVENT")

    args = argparser.parse_args()
    main(args)
